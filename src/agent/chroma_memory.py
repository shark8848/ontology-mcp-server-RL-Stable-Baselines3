#!/usr/bin/env python3
from __future__ import annotations
# Copyright (c) 2025 shark8848
# MIT License
#
# Ontology MCP Server - ç”µå•† AI åŠ©æ‰‹ç³»ç»Ÿ
# æœ¬ä½“æ¨ç† + ç”µå•†ä¸šåŠ¡é€»è¾‘ + å¯¹è¯è®°å¿† + å¯è§†åŒ– UI
#
# Author: shark8848
# Repository: https://github.com/shark8848/ontology-mcp-server
"""åŸºäº ChromaDB çš„å¯¹è¯è®°å¿†ç®¡ç†ï¼Œæ”¯æŒå‘é‡æ£€ç´¢å’ŒæŒä¹…åŒ–å­˜å‚¨ã€‚
åŠŸèƒ½:
1. ä½¿ç”¨ ChromaDB æŒä¹…åŒ–å­˜å‚¨å¯¹è¯å†å²
2. æ”¯æŒè¯­ä¹‰ç›¸ä¼¼åº¦æ£€ç´¢
3. è‡ªåŠ¨ç”Ÿæˆå¯¹è¯æ‘˜è¦
4. æ”¯æŒå¤šä¼šè¯ç®¡ç†
"""

import os
import json
import re
import shutil
from typing import List, Dict, Any, Optional
from dataclasses import dataclass, field, asdict
from datetime import datetime

try:
    import chromadb
    from chromadb.config import Settings
    CHROMA_AVAILABLE = True
except ImportError:
    CHROMA_AVAILABLE = False
    chromadb = None

from agent.logger import get_logger
from agent.memory_config import get_memory_config
from agent.user_context_extractor import UserContextManager

LOGGER = get_logger(__name__)


@dataclass
class ConversationTurn:
    """å•è½®å¯¹è¯è®°å½•"""
    turn_id: str  # å”¯ä¸€æ ‡è¯†ç¬¦
    session_id: str  # ä¼šè¯ID
    user_input: str
    agent_response: str
    tool_calls: List[Dict[str, Any]] = field(default_factory=list)
    timestamp: str = field(default_factory=lambda: datetime.now().isoformat())
    summary: Optional[str] = None
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return asdict(self)


class ChromaConversationMemory:
    """åŸºäº ChromaDB çš„å¯¹è¯è®°å¿†ç®¡ç†å™¨
    
    ç‰¹æ€§:
    - æŒä¹…åŒ–å­˜å‚¨åˆ°æœ¬åœ°ç£ç›˜
    - æ”¯æŒå‘é‡ç›¸ä¼¼åº¦æ£€ç´¢
    - è‡ªåŠ¨ç”Ÿæˆæ‘˜è¦å’Œå…ƒæ•°æ®
    - å¤šä¼šè¯éš”ç¦»
    """
    
    def __init__(
        self,
        session_id: str = None,
        persist_directory: str = None,
        collection_name: str = None,
        max_results: int = None,
        llm_model=None,
        config=None,
    ):
        """åˆå§‹åŒ– Chroma è®°å¿†ç®¡ç†å™¨
        
        Args:
            session_id: ä¼šè¯IDï¼Œç”¨äºéš”ç¦»ä¸åŒå¯¹è¯
            persist_directory: æŒä¹…åŒ–ç›®å½•ï¼Œé»˜è®¤ä»é…ç½®è¯»å–
            collection_name: Chroma collection åç§°ï¼Œé»˜è®¤ä»é…ç½®è¯»å–
            max_results: æ£€ç´¢æ—¶è¿”å›çš„æœ€å¤§ç»“æœæ•°ï¼Œé»˜è®¤ä»é…ç½®è¯»å–
            llm_model: ç”¨äºç”Ÿæˆæ‘˜è¦çš„ LLM å®ä¾‹(å¯é€‰)
            config: è®°å¿†é…ç½®å¯¹è±¡ï¼Œé»˜è®¤ä½¿ç”¨å…¨å±€é…ç½®
        """
        if not CHROMA_AVAILABLE:
            raise ImportError(
                "ChromaDB not installed. Install with: pip install chromadb"
            )
        
        # åŠ è½½é…ç½®
        if config is None:
            config = get_memory_config()
        self.config = config
        
        # åº”ç”¨é…ç½®ï¼ˆå‚æ•°ä¼˜å…ˆçº§é«˜äºé…ç½®æ–‡ä»¶ï¼‰
        self.session_id = session_id or f"{config.session.default_session_prefix}_{id(self)}"
        self.collection_name = collection_name or config.chromadb.collection_name
        
        # æ ¹æ®æ£€ç´¢æ¨¡å¼é€‰æ‹© max_results
        if max_results is None:
            if config.strategy.retrieval_mode == "recent":
                max_results = config.strategy.max_recent_turns
            else:
                max_results = config.strategy.max_similarity_results
        self.max_results = max_results
        
        # LLM æ‘˜è¦é…ç½®
        self.llm_model = llm_model
        self.enable_llm_summary = config.strategy.enable_llm_summary and llm_model is not None
        
        # æŒä¹…åŒ–ç›®å½•
        if persist_directory is None:
            persist_directory = config.chromadb.persist_directory
            # æ”¯æŒç›¸å¯¹è·¯å¾„
            if not os.path.isabs(persist_directory):
                persist_directory = os.path.join(
                    os.path.dirname(__file__), 
                    "..", "..", 
                    persist_directory
                )
        
        self.persist_directory = os.path.abspath(persist_directory)
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(self.persist_directory, exist_ok=True)
        
        # åˆå§‹åŒ– ChromaDB å®¢æˆ·ç«¯
        self.client = chromadb.PersistentClient(
            path=self.persist_directory,
            settings=Settings(
                anonymized_telemetry=False,
                allow_reset=True,
            )
        )
        
        # è·å–æˆ–åˆ›å»º collectionï¼ˆå…¼å®¹æ–°ç‰ˆæœ¬çš„ metadata é™åˆ¶ï¼‰
        self.collection = self._create_collection_with_retry()
        
        # å†…å­˜ç¼“å­˜(ç”¨äºå¿«é€Ÿè®¿é—®å½“å‰ä¼šè¯)
        self._cache: List[ConversationTurn] = []
        if config.performance.enable_cache:
            self._load_session_cache()
        
        # ç”¨æˆ·ä¸Šä¸‹æ–‡ç®¡ç†å™¨
        self.user_context_manager = UserContextManager(self.session_id)
        
        LOGGER.info(
            "ChromaDB è®°å¿†åˆå§‹åŒ–: session=%s, persist_dir=%s, collection=%s, mode=%s",
            self.session_id, self.persist_directory, self.collection_name,
            config.strategy.retrieval_mode
        )

    def _create_collection_with_retry(self):
        """åˆ›å»º collectionï¼Œå¤„ç† legacy metadata å…¼å®¹é€»è¾‘"""
        try:
            return self.client.get_or_create_collection(
                name=self.collection_name,
                metadata={"description": "Conversation memory storage"}
            )
        except Exception as exc:
            if self._is_reserved_metadata_error(exc):
                LOGGER.warning(
                    "æ£€æµ‹åˆ°æ—§ç‰ˆ Chroma å…ƒæ•°æ®æ ¼å¼(_type)ä¸å½“å‰ç‰ˆæœ¬ä¸å…¼å®¹ï¼Œå°†è‡ªåŠ¨å¤‡ä»½å¹¶é‡å»ºç´¢å¼•"
                )
                self._backup_and_reset_store()
                return self.client.get_or_create_collection(
                    name=self.collection_name,
                    metadata={"description": "Conversation memory storage"}
                )
            LOGGER.error("Failed to create Chroma collection: %s", exc)
            raise

    @staticmethod
    def _is_reserved_metadata_error(error: Exception) -> bool:
        message = str(error) if error else ""
        return "_type" in message

    def _backup_and_reset_store(self) -> None:
        """å¤‡ä»½æ—§ç‰ˆæ•°æ®å¹¶é‡ç½®å®¢æˆ·ç«¯ï¼Œé¿å… _type å…ƒæ•°æ®å¯¼è‡´çš„åˆå§‹åŒ–å¤±è´¥"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        base_name = os.path.basename(self.persist_directory.rstrip(os.sep)) or "chroma_memory"
        parent_dir = os.path.dirname(self.persist_directory.rstrip(os.sep)) or os.getcwd()
        backup_dir = os.path.join(parent_dir, f"{base_name}_legacy_{timestamp}")
        try:
            if os.path.exists(self.persist_directory):
                shutil.copytree(self.persist_directory, backup_dir, dirs_exist_ok=False)
                LOGGER.warning("å·²å¤‡ä»½æ—§ Chroma æ•°æ®åˆ°: %s", backup_dir)
        except Exception as backup_error:
            LOGGER.warning("å¤‡ä»½æ—§ Chroma æ•°æ®å¤±è´¥: %s", backup_error)
        try:
            self.client.reset()
            LOGGER.warning("æ—§ Chroma ç´¢å¼•å·²æ¸…ç©ºï¼Œå·²å‡†å¤‡é‡æ–°åˆ›å»º collection")
        except Exception as reset_error:
            LOGGER.error("é‡ç½® Chroma å®¢æˆ·ç«¯å¤±è´¥: %s", reset_error)
            raise
    
    def _load_session_cache(self):
        """ä» ChromaDB åŠ è½½å½“å‰ä¼šè¯çš„å†å²åˆ°ç¼“å­˜"""
        try:
            # æŸ¥è¯¢å½“å‰ä¼šè¯çš„æ‰€æœ‰è®°å½•
            results = self.collection.get(
                where={"session_id": self.session_id},
                include=["metadatas", "documents"]
            )
            
            if not results["ids"]:
                LOGGER.info("å½“å‰ä¼šè¯æ— å†å²è®°å½•")
                return
            
            # é‡å»ºç¼“å­˜
            self._cache.clear()
            for i, turn_id in enumerate(results["ids"]):
                metadata = results["metadatas"][i]
                doc = results["documents"][i]
                
                turn = ConversationTurn(
                    turn_id=turn_id,
                    session_id=metadata["session_id"],
                    user_input=metadata["user_input"],
                    agent_response=metadata["agent_response"],
                    tool_calls=json.loads(metadata.get("tool_calls", "[]")),
                    timestamp=metadata["timestamp"],
                    summary=doc,  # document å­˜å‚¨æ‘˜è¦
                    metadata=metadata,
                )
                self._cache.append(turn)
            
            # æŒ‰æ—¶é—´æ’åº
            self._cache.sort(key=lambda x: x.timestamp)
            
            LOGGER.info("ä» ChromaDB åŠ è½½ %d æ¡å†å²è®°å½•åˆ°ç¼“å­˜", len(self._cache))
            
        except Exception as e:
            LOGGER.warning("åŠ è½½ä¼šè¯ç¼“å­˜å¤±è´¥: %s", e)
    
    def _generate_summary(self, turn: ConversationTurn) -> str:
        """ç”Ÿæˆå¯¹è¯æ‘˜è¦
        
        Args:
            turn: å¯¹è¯è½®æ¬¡
            
        Returns:
            str: æ‘˜è¦æ–‡æœ¬
        """
        # åŸºç¡€è§„åˆ™æ‘˜è¦
        user_summary = turn.user_input[:100]
        
        tool_summary = ""
        if turn.tool_calls:
            tool_names = [tc.get("tool", "unknown") for tc in turn.tool_calls]
            tool_summary = f", è°ƒç”¨å·¥å…·: {', '.join(tool_names)}"
        
        response_summary = turn.agent_response[:50]
        if len(turn.agent_response) > 50:
            response_summary += "..."
        
        summary = f"ç”¨æˆ·: {user_summary}{tool_summary} â†’ {response_summary}"
        
        # å¦‚æœæœ‰ LLMï¼Œå°è¯•ç”Ÿæˆæ›´å¥½çš„æ‘˜è¦
        if self.llm_model:
            try:
                summary_prompt = f"""è¯·ä¸ºä»¥ä¸‹å¯¹è¯ç”Ÿæˆç®€æ´æ‘˜è¦(ä¸è¶…è¿‡50å­—):

ç”¨æˆ·: {turn.user_input}
Agent: {turn.agent_response}

æ‘˜è¦:"""
                messages = [{"role": "user", "content": summary_prompt}]
                response = self.llm_model.generate(messages, tools=[])
                llm_summary = response.get("content", "").strip()
                
                if llm_summary:
                    summary = llm_summary
                    LOGGER.debug("ä½¿ç”¨ LLM ç”Ÿæˆæ‘˜è¦")
            except Exception as e:
                LOGGER.warning("LLM æ‘˜è¦ç”Ÿæˆå¤±è´¥: %s, ä½¿ç”¨åŸºç¡€æ‘˜è¦", e)
        
        return summary
    
    def add_turn(
        self, 
        user_input: str, 
        agent_response: str, 
        tool_calls: List[Dict[str, Any]] = None,
        metadata: Dict[str, Any] = None,
    ) -> ConversationTurn:
        """æ·»åŠ ä¸€è½®å¯¹è¯åˆ°è®°å¿†
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            agent_response: Agent å“åº”
            tool_calls: å·¥å…·è°ƒç”¨åˆ—è¡¨
            metadata: é¢å¤–å…ƒæ•°æ®
            
        Returns:
            ConversationTurn: æ–°å¢çš„å¯¹è¯è®°å½•
        """
        # ç”Ÿæˆå”¯ä¸€ID
        turn_id = f"{self.session_id}_{datetime.now().timestamp()}"
        
        # åˆ›å»ºå¯¹è¯è®°å½•
        turn = ConversationTurn(
            turn_id=turn_id,
            session_id=self.session_id,
            user_input=user_input,
            agent_response=agent_response,
            tool_calls=tool_calls or [],
            metadata=metadata or {},
        )
        
        # ğŸ¯ æ›´æ–°ç”¨æˆ·ä¸Šä¸‹æ–‡ï¼ˆåŠ¨æ€æå–å…³é”®ä¿¡æ¯ï¼‰
        self.user_context_manager.update_from_conversation(
            user_input, agent_response, tool_calls
        )

        # å¯¹äº create_order å·¥å…·ï¼Œå¼ºåˆ¶ä» observation æˆ– input ä¸­æå–å¹¶æ˜¾å¼è®¾ç½®æœ€è¿‘è®¢å•å·ï¼Œé¿å…è¯¯è¦†ç›–æˆ–é—æ¼
        try:
            if tool_calls:
                for tc in tool_calls:
                    tname = (tc.get('tool') or '').lower()
                    if 'create_order' in tname:
                        obs = tc.get('observation') or ''
                        inp = tc.get('input') or {}
                        # ä¼˜å…ˆä» observation ä¸­æå– ORD æ ¼å¼è®¢å•å·
                        m = re.search(r"\b(ORD\d{15,})\b", str(obs))
                        if m:
                            self.user_context_manager.set_recent_order(m.group(1))
                            continue

                        # å¦‚æœ observation ä¸­æ²¡æœ‰ï¼Œä» inputï¼ˆå¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–dictï¼‰ä¸­å°è¯•æå–
                        if isinstance(inp, str):
                            m2 = re.search(r"\b(ORD\d{15,})\b", inp)
                            if m2:
                                self.user_context_manager.set_recent_order(m2.group(1))
                                continue
                        elif isinstance(inp, dict):
                            # æœ‰äº›å·¥å…·è¿”å› order_id å­—æ®µ
                            oid = inp.get('order_id') or inp.get('order_no') or inp.get('order')
                            if oid and isinstance(oid, str):
                                m3 = re.search(r"\b(ORD\d{15,})\b", oid)
                                if m3:
                                    self.user_context_manager.set_recent_order(m3.group(1))
                                    continue
        except Exception:
            LOGGER.exception("åœ¨ create_order åå¼ºåˆ¶è®¾ç½®æœ€è¿‘è®¢å•å·æ—¶å‡ºé”™")
        
        # ç”Ÿæˆæ‘˜è¦
        turn.summary = self._generate_summary(turn)
        
        # å‡†å¤‡å…ƒæ•°æ®
        chroma_metadata = {
            "session_id": self.session_id,
            "user_input": user_input[:500],  # é™åˆ¶é•¿åº¦é¿å…è¶…é™
            "agent_response": agent_response[:500],
            "tool_calls": json.dumps(tool_calls or []),
            "timestamp": turn.timestamp,
        }
        # åˆå¹¶é¢å¤–å…ƒæ•°æ®
        if metadata:
            chroma_metadata.update(metadata)
        chroma_metadata = self._sanitize_metadata(chroma_metadata)
        
        # å­˜å‚¨åˆ° ChromaDB
        try:
            self.collection.add(
                ids=[turn_id],
                documents=[turn.summary],  # æ‘˜è¦ä½œä¸ºå¯æ£€ç´¢æ–‡æ¡£
                metadatas=[chroma_metadata],
            )
            LOGGER.info("æ–°å¢å¯¹è¯è®°å½•: turn_id=%s", turn_id)
        except Exception as e:
            LOGGER.error("å­˜å‚¨å¯¹è¯è®°å½•å¤±è´¥: %s", e)
            raise
        
        # æ›´æ–°ç¼“å­˜
        self._cache.append(turn)
        
        return turn

    def _sanitize_metadata(self, metadata: Dict[str, Any]) -> Dict[str, Any]:
        """è¿‡æ»¤æ‰ä»¥ä¸‹åˆ’çº¿å¼€å¤´çš„é”®ï¼Œå¹¶ç¡®ä¿å€¼å¯åºåˆ—åŒ–"""
        if not metadata:
            return {}
        sanitized: Dict[str, Any] = {}
        for key, value in metadata.items():
            sanitized_key = str(key)
            if sanitized_key.startswith("_"):
                sanitized_key = sanitized_key.lstrip("_") or "meta"
                LOGGER.debug("æ£€æµ‹åˆ°ä»¥ä¸‹åˆ’çº¿å¼€å¤´çš„å…ƒæ•°æ®é”®ï¼Œå·²è‡ªåŠ¨é‡å‘½å: %s", key)
            sanitized[sanitized_key] = self._coerce_metadata_value(value)
        return sanitized

    @staticmethod
    def _coerce_metadata_value(value: Any) -> Any:
        if isinstance(value, (str, int, float, bool)) or value is None:
            return value
        try:
            return json.dumps(value, ensure_ascii=False)
        except Exception:
            return str(value)
    
    def get_recent_turns(self, n: int = 5) -> List[ConversationTurn]:
        """è·å–æœ€è¿‘Nè½®å¯¹è¯
        
        Args:
            n: è¿”å›çš„å¯¹è¯è½®æ•°
            
        Returns:
            List[ConversationTurn]: å¯¹è¯åˆ—è¡¨
        """
        return self._cache[-n:] if self._cache else []
    
    def search_similar(
        self, 
        query: str, 
        n_results: int = None
    ) -> List[ConversationTurn]:
        """åŸºäºè¯­ä¹‰ç›¸ä¼¼åº¦æœç´¢å†å²å¯¹è¯
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            n_results: è¿”å›ç»“æœæ•°é‡ï¼Œé»˜è®¤ä½¿ç”¨ max_results
            
        Returns:
            List[ConversationTurn]: ç›¸ä¼¼å¯¹è¯åˆ—è¡¨
        """
        if n_results is None:
            n_results = self.max_results
        
        try:
            results = self.collection.query(
                query_texts=[query],
                n_results=min(n_results, len(self._cache)),
                where={"session_id": self.session_id},
                include=["metadatas", "documents", "distances"]
            )
            
            if not results["ids"] or not results["ids"][0]:
                return []
            
            # é‡å»ºå¯¹è¯è®°å½•
            similar_turns = []
            for i, turn_id in enumerate(results["ids"][0]):
                metadata = results["metadatas"][0][i]
                doc = results["documents"][0][i]
                distance = results["distances"][0][i]
                
                turn = ConversationTurn(
                    turn_id=turn_id,
                    session_id=metadata["session_id"],
                    user_input=metadata["user_input"],
                    agent_response=metadata["agent_response"],
                    tool_calls=json.loads(metadata.get("tool_calls", "[]")),
                    timestamp=metadata["timestamp"],
                    summary=doc,
                    metadata={**metadata, "similarity_distance": distance},
                )
                similar_turns.append(turn)
            
            LOGGER.debug("ç›¸ä¼¼åº¦æ£€ç´¢è¿”å› %d æ¡ç»“æœ", len(similar_turns))
            return similar_turns
            
        except Exception as e:
            LOGGER.error("ç›¸ä¼¼åº¦æ£€ç´¢å¤±è´¥: %s", e)
            return []
    
    def get_context_for_prompt(
        self, 
        use_similarity: bool = False,
        query: str = None,
        max_turns: int = 5,
    ) -> str:
        """è·å–ç”¨äºæ³¨å…¥ prompt çš„ä¸Šä¸‹æ–‡
        
        Args:
            use_similarity: æ˜¯å¦ä½¿ç”¨ç›¸ä¼¼åº¦æ£€ç´¢
            query: æŸ¥è¯¢æ–‡æœ¬(ä»…åœ¨ use_similarity=True æ—¶ä½¿ç”¨)
            max_turns: æœ€å¤§è¿”å›è½®æ•°
            
        Returns:
            str: æ ¼å¼åŒ–çš„ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
        """
        context_parts = []
        
        # ğŸ¯ ç¬¬ä¸€éƒ¨åˆ†ï¼šç”¨æˆ·ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆå…³é”®ï¼ï¼‰
        user_context = self.user_context_manager.get_prompt_injection()
        if user_context:
            context_parts.append(user_context)
        
        # ç¬¬äºŒéƒ¨åˆ†ï¼šå¯¹è¯å†å²
        if use_similarity and query:
            turns = self.search_similar(query, max_turns)
        else:
            turns = self.get_recent_turns(max_turns)
        
        if turns:
            context_lines = ["**å¯¹è¯å†å²æ‘˜è¦**:"]
            for i, turn in enumerate(turns, 1):
                # æ˜¾ç¤ºå®Œæ•´çš„ç”¨æˆ·é—®é¢˜å’Œæ‘˜è¦
                user_q = turn.user_input[:80]
                if len(turn.user_input) > 80:
                    user_q += "..."
                context_lines.append(f"{i}. ç”¨æˆ·: {user_q}")
                context_lines.append(f"   å›å¤: {turn.summary}")
            
            context_parts.append("\n".join(context_lines))
            LOGGER.debug("ç”Ÿæˆä¸Šä¸‹æ–‡: %d è½®æ‘˜è¦", len(turns))
        
        return "\n\n".join(context_parts) if context_parts else ""
    
    def get_full_history(self) -> List[Dict[str, Any]]:
        """è·å–å½“å‰ä¼šè¯çš„å®Œæ•´å†å²
        
        Returns:
            List[Dict]: å†å²è®°å½•åˆ—è¡¨
        """
        return [turn.to_dict() for turn in self._cache]
    
    def clear_session(self):
        """æ¸…ç©ºå½“å‰ä¼šè¯çš„è®°å¿†"""
        try:
            # è·å–å½“å‰ä¼šè¯çš„æ‰€æœ‰è®°å½•ID
            results = self.collection.get(
                where={"session_id": self.session_id}
            )
            
            if results["ids"]:
                # åˆ é™¤è®°å½•
                self.collection.delete(ids=results["ids"])
                LOGGER.info("æ¸…ç©ºä¼šè¯è®°å¿†: åˆ é™¤ %d æ¡è®°å½•", len(results["ids"]))
            
            # æ¸…ç©ºç¼“å­˜
            self._cache.clear()
            
            # ğŸ¯ æ¸…ç©ºç”¨æˆ·ä¸Šä¸‹æ–‡
            self.user_context_manager.clear()
            
        except Exception as e:
            LOGGER.error("æ¸…ç©ºä¼šè¯å¤±è´¥: %s", e)
    
    def delete_collection(self):
        """åˆ é™¤æ•´ä¸ª collectionï¼ˆæ…ç”¨ï¼‰"""
        try:
            self.client.delete_collection(name=self.collection_name)
            LOGGER.warning("å·²åˆ é™¤ collection: %s", self.collection_name)
        except Exception as e:
            LOGGER.error("åˆ é™¤ collection å¤±è´¥: %s", e)
    
    def get_session_stats(self) -> Dict[str, Any]:
        """è·å–ä¼šè¯ç»Ÿè®¡ä¿¡æ¯"""
        user_ctx = self.user_context_manager.get_context()
        return {
            "session_id": self.session_id,
            "total_turns": len(self._cache),
            "persist_directory": self.persist_directory,
            "collection_name": self.collection_name,
            "user_context": {
                "user_id": user_ctx.user_id,
                "has_phone": bool(user_ctx.phone),
                "order_count": len(user_ctx.order_ids),
                "product_count": len(user_ctx.viewed_product_ids),
            }
        }
    
    @classmethod
    def list_sessions(cls, persist_directory: str = None) -> List[str]:
        """åˆ—å‡ºæ‰€æœ‰ä¼šè¯ID
        
        Args:
            persist_directory: æŒä¹…åŒ–ç›®å½•
            
        Returns:
            List[str]: ä¼šè¯IDåˆ—è¡¨
        """
        if not CHROMA_AVAILABLE:
            return []
        
        if persist_directory is None:
            persist_directory = os.path.join(
                os.path.dirname(__file__), 
                "..", "..", "data", "chroma_memory"
            )
        
        try:
            client = chromadb.PersistentClient(path=persist_directory)
            collections = client.list_collections()
            
            sessions = set()
            for col in collections:
                results = col.get(include=["metadatas"])
                for metadata in results.get("metadatas", []):
                    if "session_id" in metadata:
                        sessions.add(metadata["session_id"])
            
            return sorted(sessions)
            
        except Exception as e:
            LOGGER.error("åˆ—å‡ºä¼šè¯å¤±è´¥: %s", e)
            return []


# å‘åå…¼å®¹çš„åˆ«å
ConversationMemory = ChromaConversationMemory
