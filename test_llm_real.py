#!/usr/bin/env python3
"""
æœ€å°åŒ–æµ‹è¯•ï¼šLLMæ˜¯å¦ä¼šè°ƒç”¨å›¾è¡¨å·¥å…·
"""

import sys
import json
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent / "src"))

def test_llm_tool_call():
    """æµ‹è¯•LLMæ˜¯å¦çœŸçš„ä¼šè°ƒç”¨analytics_get_chart_data"""
    print("=" * 70)
    print("ğŸ”¬ æµ‹è¯•LLMå›¾è¡¨å·¥å…·è°ƒç”¨")
    print("=" * 70)
    
    # å¯¼å…¥
    from agent.llm_deepseek import get_default_chat_model
    from agent.mcp_adapter import MCPAdapter
    
    # åˆå§‹åŒ–
    llm = get_default_chat_model()
    adapter = MCPAdapter()
    tools = adapter.create_tools()
    tool_specs = [t.to_openai_tool() for t in tools]
    
    print(f"\nâœ… LLM æ¨¡å‹: {llm.model}")
    print(f"âœ… API URL: {llm.client.base_url}")
    print(f"âœ… å·¥å…·æ•°é‡: {len(tool_specs)}")
    
    # ç¡®è®¤å›¾è¡¨å·¥å…·å­˜åœ¨
    chart_tool = None
    for spec in tool_specs:
        if spec["function"]["name"] == "analytics_get_chart_data":
            chart_tool = spec
            break
    
    if not chart_tool:
        print("âŒ å›¾è¡¨å·¥å…·ä¸å­˜åœ¨!")
        return False
    
    print("\nâœ… å›¾è¡¨å·¥å…·å®šä¹‰:")
    print(json.dumps(chart_tool, indent=2, ensure_ascii=False))
    
    # æ„å»ºæ¶ˆæ¯
    system_prompt = """ä½ æ˜¯ç”µå•†åŠ©æ‰‹ã€‚ä½ æœ‰ä»¥ä¸‹å·¥å…·ï¼š

- analytics_get_chart_data: ç”Ÿæˆæ•°æ®å¯è§†åŒ–å›¾è¡¨ï¼ˆè¶‹åŠ¿å›¾ã€æŸ±çŠ¶å›¾ã€é¥¼å›¾ã€å¯¹æ¯”å›¾ï¼‰
  å‚æ•°: chart_typeï¼ˆtrend/pie/bar/comparisonï¼‰ã€daysï¼ˆå¤©æ•°ï¼‰ã€top_nï¼ˆæ’åæ•°é‡ï¼‰

**é‡è¦è§„åˆ™**ï¼š
- ç”¨æˆ·è¯´"æŸ±çŠ¶å›¾"ã€"æ’è¡Œ" â†’ è°ƒç”¨ analytics_get_chart_data(chart_type="bar")
- ç”¨æˆ·è¯´"è¶‹åŠ¿å›¾"ã€"èµ°åŠ¿" â†’ è°ƒç”¨ analytics_get_chart_data(chart_type="trend")
- ç”¨æˆ·è¯´"é¥¼å›¾"ã€"å æ¯”" â†’ è°ƒç”¨ analytics_get_chart_data(chart_type="pie")
- ç”¨æˆ·è¯´"å¯¹æ¯”"ã€"æ¯”è¾ƒ" â†’ è°ƒç”¨ analytics_get_chart_data(chart_type="comparison")

ç¤ºä¾‹ï¼š
ç”¨æˆ·ï¼š"æ˜¾ç¤ºé”€é‡å‰10çš„å•†å“æŸ±çŠ¶å›¾"
ä½ åº”è¯¥ï¼šanalytics_get_chart_data(chart_type="bar", top_n=10)

ç”¨æˆ·ï¼š"å±•ç¤ºæœ€è¿‘7å¤©è®¢å•è¶‹åŠ¿"
ä½ åº”è¯¥ï¼šanalytics_get_chart_data(chart_type="trend", days=7)

**å¿…é¡»è°ƒç”¨å·¥å…·ï¼Œä¸è¦åªç”¨æ–‡å­—æè¿°ï¼**"""

    user_message = "æ˜¾ç¤ºé”€é‡å‰10çš„å•†å“æŸ±çŠ¶å›¾"
    
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_message}
    ]
    
    print("\n" + "=" * 70)
    print("ğŸ“¤ å‘é€ç»™LLM")
    print("=" * 70)
    print(f"\nç”¨æˆ·æ¶ˆæ¯: {user_message}")
    print(f"ç³»ç»Ÿæç¤ºé•¿åº¦: {len(system_prompt)} å­—ç¬¦")
    print(f"å·¥å…·: {len(tool_specs)} ä¸ª")
    
    # è°ƒç”¨LLM
    print("\nâ³ è°ƒç”¨LLM...")
    try:
        result = llm.generate(messages, tools=tool_specs)
    except Exception as e:
        print(f"\nâŒ LLMè°ƒç”¨å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # åˆ†æå“åº”
    print("\n" + "=" * 70)
    print("ğŸ“¥ LLMå“åº”")
    print("=" * 70)
    
    content = result.get("content", "")
    tool_calls = result.get("tool_calls", [])
    
    print(f"\nå†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
    if content:
        print(f"å†…å®¹é¢„è§ˆ: {content[:200]}...")
    
    print(f"\nå·¥å…·è°ƒç”¨: {len(tool_calls)} ä¸ª")
    
    if tool_calls:
        print("\nâœ… LLMè°ƒç”¨äº†å·¥å…·!")
        for i, call in enumerate(tool_calls, 1):
            print(f"\n  å·¥å…· {i}:")
            print(f"    ID: {call.get('id')}")
            print(f"    åç§°: {call.get('name')}")
            print(f"    å‚æ•°: {json.dumps(call.get('arguments', {}), ensure_ascii=False)}")
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯å›¾è¡¨å·¥å…·
            if call.get('name') == 'analytics_get_chart_data':
                args = call.get('arguments', {})
                chart_type = args.get('chart_type')
                print(f"\n    ğŸ‰ è°ƒç”¨äº†å›¾è¡¨å·¥å…·!")
                print(f"    å›¾è¡¨ç±»å‹: {chart_type}")
                
                # æ£€æŸ¥å‚æ•°æ­£ç¡®æ€§
                if chart_type == 'bar':
                    print("    âœ… å›¾è¡¨ç±»å‹æ­£ç¡® (bar)")
                else:
                    print(f"    âš ï¸  å›¾è¡¨ç±»å‹å¯èƒ½ä¸æ­£ç¡®: {chart_type} (æœŸæœ› bar)")
                
                top_n = args.get('top_n')
                if top_n:
                    print(f"    âœ… top_nå‚æ•°: {top_n}")
                else:
                    print("    âš ï¸  ç¼ºå°‘top_nå‚æ•°")
                
                return True
        
        print("\nâš ï¸  LLMè°ƒç”¨äº†å·¥å…·ï¼Œä½†ä¸æ˜¯å›¾è¡¨å·¥å…·")
        return False
    else:
        print("\nâŒ LLMæ²¡æœ‰è°ƒç”¨ä»»ä½•å·¥å…·!")
        print(f"\nLLMåªè¿”å›äº†æ–‡å­—:\n{content}")
        return False


def test_multiple_queries():
    """æµ‹è¯•å¤šä¸ªæŸ¥è¯¢"""
    queries = [
        "æ˜¾ç¤ºé”€é‡å‰10çš„å•†å“æŸ±çŠ¶å›¾",
        "å±•ç¤ºæœ€è¿‘7å¤©è®¢å•è¶‹åŠ¿å›¾",
        "ç”Ÿæˆå•†å“åˆ†ç±»é”€é‡é¥¼å›¾",
    ]
    
    results = {}
    
    for query in queries:
        print(f"\n\n{'=' * 70}")
        print(f"æµ‹è¯•: {query}")
        print("=" * 70)
        
        result = test_specific_query(query)
        results[query] = result
        
        if result:
            print(f"\nâœ… æˆåŠŸ")
        else:
            print(f"\nâŒ å¤±è´¥")
    
    print("\n\n" + "=" * 70)
    print("æ±‡æ€»")
    print("=" * 70)
    
    for query, success in results.items():
        status = "âœ…" if success else "âŒ"
        print(f"{status} {query}")
    
    success_count = sum(results.values())
    total_count = len(results)
    
    print(f"\næˆåŠŸç‡: {success_count}/{total_count} ({success_count/total_count*100:.0f}%)")
    
    return success_count == total_count


def test_specific_query(query: str) -> bool:
    """æµ‹è¯•ç‰¹å®šæŸ¥è¯¢"""
    from agent.llm_deepseek import get_default_chat_model
    from agent.mcp_adapter import MCPAdapter
    
    llm = get_default_chat_model()
    adapter = MCPAdapter()
    tools = adapter.create_tools()
    tool_specs = [t.to_openai_tool() for t in tools]
    
    system_prompt = """ä½ æ˜¯ç”µå•†åŠ©æ‰‹ã€‚ç”¨æˆ·è¦æ±‚å›¾è¡¨æ—¶ï¼Œå¿…é¡»è°ƒç”¨ analytics_get_chart_data å·¥å…·ã€‚

å…³é”®è¯ï¼šæŸ±çŠ¶å›¾ã€æ’è¡Œ â†’ chart_type="bar"
å…³é”®è¯ï¼šè¶‹åŠ¿å›¾ã€èµ°åŠ¿ â†’ chart_type="trend"
å…³é”®è¯ï¼šé¥¼å›¾ã€å æ¯” â†’ chart_type="pie"""

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": query}
    ]
    
    try:
        result = llm.generate(messages, tools=tool_specs)
        tool_calls = result.get("tool_calls", [])
        
        for call in tool_calls:
            if call.get('name') == 'analytics_get_chart_data':
                return True
        
        return False
    except Exception as e:
        print(f"é”™è¯¯: {e}")
        return False


def main():
    print("\nğŸ”¬ å›¾è¡¨å·¥å…·è°ƒç”¨æµ‹è¯•\n")
    
    # å…ˆæµ‹è¯•å•ä¸ªæŸ¥è¯¢
    success = test_llm_tool_call()
    
    if success:
        print("\n\nâœ… åŸºç¡€æµ‹è¯•é€šè¿‡ï¼LLMä¼šè°ƒç”¨å›¾è¡¨å·¥å…·ã€‚")
        print("\nç»§ç»­æµ‹è¯•å¤šä¸ªæŸ¥è¯¢...")
        test_multiple_queries()
    else:
        print("\n\nâŒ åŸºç¡€æµ‹è¯•å¤±è´¥ï¼LLMä¸è°ƒç”¨å›¾è¡¨å·¥å…·ã€‚")
        print("\nå¯èƒ½çš„åŸå› :")
        print("  1. System prompt ä¸å¤Ÿæ˜ç¡®")
        print("  2. LLM æ¨¡å‹æœ¬èº«çš„è¡Œä¸ºé—®é¢˜")
        print("  3. å·¥å…·å®šä¹‰æè¿°ä¸å¤Ÿæ¸…æ¥š")
        print("  4. LLM temperature è¿‡é«˜å¯¼è‡´ä¸ç¨³å®š")
        
    return 0


if __name__ == "__main__":
    sys.exit(main())
